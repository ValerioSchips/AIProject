{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Recomender Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dABS7x_2MHBD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BK42mwVZcP1m"
   },
   "outputs": [],
   "source": [
    "#read file line-by-line and parse json, returns dataframe\n",
    "def parse_json(filename_gzipped_python_json, read_max=-1):\n",
    "  #read gzipped content\n",
    "  f=gzip.open(filename_gzipped_python_json,'r')\n",
    "  \n",
    "  #parse json\n",
    "  parse_data = []\n",
    "  for line in tqdm(f): #tqdm is for showing progress bar, always good when processing large amounts of data\n",
    "    line = line.decode('utf-8')\n",
    "    line = line.replace('true','True') #difference json/python\n",
    "    line = line.replace('false','False')\n",
    "    parsed_result = eval(line) #load python nested datastructure\n",
    "    parse_data.append(parsed_result)\n",
    "    if read_max !=-1 and len(parse_data) > read_max:\n",
    "      print(f'Break reading after {read_max} records')\n",
    "      break\n",
    "  print(f\"Reading {len(parse_data)} rows.\")\n",
    "\n",
    "  #create dataframe\n",
    "  df= pd.DataFrame.from_dict(parse_data)\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxnlmqofYTU-"
   },
   "source": [
    "# 1. Load Goodreads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y6O79-jSYqqF"
   },
   "outputs": [],
   "source": [
    "goodreads_path = './'\n",
    "books = 'goodreads_books_comics_graphic.json.gz'\n",
    "interactions = 'goodreads_interactions_comics_graphic.json.gz'\n",
    "reviews = 'goodreads_reviews_comics_graphic.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TxtZ0gxoH4F"
   },
   "source": [
    "# 2. Clean data\n",
    "Example of:\n",
    "- Merging two files\n",
    "- tqdm pd.progress_apply\n",
    "- Example of non-destructive transforms, i.e. keep original data and make re-running cell works\n",
    "- Parsing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Om9frMPmom2_",
    "outputId": "75853dda-30a5-4029-a3cf-a3a892467fab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>publication_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25742454</td>\n",
       "      <td>The Switchblade Mamma</td>\n",
       "      <td>[{'author_id': '8551671', 'role': ''}]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30128855</td>\n",
       "      <td>Cruelle</td>\n",
       "      <td>[{'author_id': '3274315', 'role': ''}]</td>\n",
       "      <td>Dargaud</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13571772</td>\n",
       "      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n",
       "      <td>[{'author_id': '37450', 'role': ''}]</td>\n",
       "      <td>Hachette Partworks Ltd.</td>\n",
       "      <td>146</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35452242</td>\n",
       "      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n",
       "      <td>[{'author_id': '16209952', 'role': ''}, {'auth...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>707611</td>\n",
       "      <td>Superman Archives, Vol. 2</td>\n",
       "      <td>[{'author_id': '81563', 'role': ''}, {'author_...</td>\n",
       "      <td>DC Comics</td>\n",
       "      <td>272</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                                              title  \\\n",
       "0  25742454                              The Switchblade Mamma   \n",
       "1  30128855                                            Cruelle   \n",
       "2  13571772  Captain America: Winter Soldier (The Ultimate ...   \n",
       "3  35452242  Bounty Hunter 4/3: My Life in Combat from Mari...   \n",
       "4    707611                          Superman Archives, Vol. 2   \n",
       "\n",
       "                                             authors                publisher  \\\n",
       "0             [{'author_id': '8551671', 'role': ''}]                            \n",
       "1             [{'author_id': '3274315', 'role': ''}]                  Dargaud   \n",
       "2               [{'author_id': '37450', 'role': ''}]  Hachette Partworks Ltd.   \n",
       "3  [{'author_id': '16209952', 'role': ''}, {'auth...                            \n",
       "4  [{'author_id': '81563', 'role': ''}, {'author_...                DC Comics   \n",
       "\n",
       "  num_pages publication_year  \n",
       "0                             \n",
       "1                       2016  \n",
       "2       146             2012  \n",
       "3                             \n",
       "4       272             1997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#books\n",
    "books_df = pd.read_json(goodreads_path + books, lines=True)\n",
    "books_df = books_df[['book_id',\t'title','authors',\t'publisher',\t'num_pages',\t'publication_year']]\n",
    "display(books_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2U3DuZiD8VV5",
    "outputId": "819707b2-922a-4b72-ffc5-74611fece4b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>name</th>\n",
       "      <th>ratings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.98</td>\n",
       "      <td>604031</td>\n",
       "      <td>7</td>\n",
       "      <td>Ronald J. Fields</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.08</td>\n",
       "      <td>626222</td>\n",
       "      <td>28716</td>\n",
       "      <td>Anita Diamant</td>\n",
       "      <td>546796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.92</td>\n",
       "      <td>10333</td>\n",
       "      <td>5075</td>\n",
       "      <td>Barbara Hambly</td>\n",
       "      <td>122118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.68</td>\n",
       "      <td>9212</td>\n",
       "      <td>36262</td>\n",
       "      <td>Jennifer Weiner</td>\n",
       "      <td>888522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.82</td>\n",
       "      <td>149918</td>\n",
       "      <td>96</td>\n",
       "      <td>Nigel Pennick</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_rating  author_id  text_reviews_count              name  \\\n",
       "0            3.98     604031                   7  Ronald J. Fields   \n",
       "1            4.08     626222               28716     Anita Diamant   \n",
       "2            3.92      10333                5075    Barbara Hambly   \n",
       "3            3.68       9212               36262   Jennifer Weiner   \n",
       "4            3.82     149918                  96     Nigel Pennick   \n",
       "\n",
       "   ratings_count  \n",
       "0             49  \n",
       "1         546796  \n",
       "2         122118  \n",
       "3         888522  \n",
       "4           1740  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get author names (authors metadata is an additional dowload from goodreads)\n",
    "authors = 'goodreads_book_authors.json.gz'\n",
    "authors_df =  pd.read_json(goodreads_path + authors, lines=True) #829.529 authors (also non-graphic and comics)\n",
    "display(authors_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "NiQ5u0yk9b0x",
    "outputId": "e7cb29f3-cd03-40c2-dc92-163b2ff677a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829529/829529 [00:43<00:00, 19290.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>publication_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25742454</td>\n",
       "      <td>The Switchblade Mamma</td>\n",
       "      <td>[{'author_id': '8551671', 'role': ''}]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30128855</td>\n",
       "      <td>Cruelle</td>\n",
       "      <td>[{'author_id': '3274315', 'role': ''}]</td>\n",
       "      <td>Dargaud</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13571772</td>\n",
       "      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n",
       "      <td>[{'author_id': '37450', 'role': ''}]</td>\n",
       "      <td>Hachette Partworks Ltd.</td>\n",
       "      <td>146</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35452242</td>\n",
       "      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n",
       "      <td>[{'author_id': '16209952', 'role': ''}, {'auth...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>707611</td>\n",
       "      <td>Superman Archives, Vol. 2</td>\n",
       "      <td>[{'author_id': '81563', 'role': ''}, {'author_...</td>\n",
       "      <td>DC Comics</td>\n",
       "      <td>272</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                                              title  \\\n",
       "0  25742454                              The Switchblade Mamma   \n",
       "1  30128855                                            Cruelle   \n",
       "2  13571772  Captain America: Winter Soldier (The Ultimate ...   \n",
       "3  35452242  Bounty Hunter 4/3: My Life in Combat from Mari...   \n",
       "4    707611                          Superman Archives, Vol. 2   \n",
       "\n",
       "                                             authors                publisher  \\\n",
       "0             [{'author_id': '8551671', 'role': ''}]                            \n",
       "1             [{'author_id': '3274315', 'role': ''}]                  Dargaud   \n",
       "2               [{'author_id': '37450', 'role': ''}]  Hachette Partworks Ltd.   \n",
       "3  [{'author_id': '16209952', 'role': ''}, {'auth...                            \n",
       "4  [{'author_id': '81563', 'role': ''}, {'author_...                DC Comics   \n",
       "\n",
       "  num_pages publication_year  \n",
       "0                             \n",
       "1                       2016  \n",
       "2       146             2012  \n",
       "3                             \n",
       "4       272             1997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25742454</td>\n",
       "      <td>The Switchblade Mamma</td>\n",
       "      <td>[{'author_id': '8551671', 'role': ''}]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Lindsey Schussman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30128855</td>\n",
       "      <td>Cruelle</td>\n",
       "      <td>[{'author_id': '3274315', 'role': ''}]</td>\n",
       "      <td>Dargaud</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>Florence Dupre la Tour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13571772</td>\n",
       "      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n",
       "      <td>[{'author_id': '37450', 'role': ''}]</td>\n",
       "      <td>Hachette Partworks Ltd.</td>\n",
       "      <td>146</td>\n",
       "      <td>2012</td>\n",
       "      <td>Ed Brubaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35452242</td>\n",
       "      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n",
       "      <td>[{'author_id': '16209952', 'role': ''}, {'auth...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Jason Delgado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>707611</td>\n",
       "      <td>Superman Archives, Vol. 2</td>\n",
       "      <td>[{'author_id': '81563', 'role': ''}, {'author_...</td>\n",
       "      <td>DC Comics</td>\n",
       "      <td>272</td>\n",
       "      <td>1997</td>\n",
       "      <td>Jerry Siegel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                                              title  \\\n",
       "0  25742454                              The Switchblade Mamma   \n",
       "1  30128855                                            Cruelle   \n",
       "2  13571772  Captain America: Winter Soldier (The Ultimate ...   \n",
       "3  35452242  Bounty Hunter 4/3: My Life in Combat from Mari...   \n",
       "4    707611                          Superman Archives, Vol. 2   \n",
       "\n",
       "                                             authors                publisher  \\\n",
       "0             [{'author_id': '8551671', 'role': ''}]                            \n",
       "1             [{'author_id': '3274315', 'role': ''}]                  Dargaud   \n",
       "2               [{'author_id': '37450', 'role': ''}]  Hachette Partworks Ltd.   \n",
       "3  [{'author_id': '16209952', 'role': ''}, {'auth...                            \n",
       "4  [{'author_id': '81563', 'role': ''}, {'author_...                DC Comics   \n",
       "\n",
       "  num_pages publication_year             author_name  \n",
       "0                                  Lindsey Schussman  \n",
       "1                       2016  Florence Dupre la Tour  \n",
       "2       146             2012             Ed Brubaker  \n",
       "3                                      Jason Delgado  \n",
       "4       272             1997            Jerry Siegel  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#merge, but inline for each row, since each book has many authors\n",
    "author_id_to_name = {}\n",
    "for idx, row in tqdm(authors_df.iterrows(), total=authors_df.shape[0]):\n",
    "  author_id_to_name[row['author_id']] = row['name']\n",
    "display(books_df.head(5))\n",
    "#important: type of author is np.int64\n",
    "books_df['author_name'] = books_df['authors'].apply(lambda authors_dct_lst: author_id_to_name.get(np.int64(authors_dct_lst[0]['author_id'])))\n",
    "display(books_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "-rhpQ7QysSE9",
    "outputId": "137f082d-538d-40bd-d0a8-923a251eae0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7347630it [05:12, 23492.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 7347630 rows.\n"
     ]
    }
   ],
   "source": [
    "#interactions\n",
    "#wc -l interactions is 7.347.630 \n",
    "#sample first 500.000 interactions\n",
    "interactions_df = parse_json(goodreads_path + interactions)# , read_max=500000) #Note: RAM issue if loading with pd.read_json, no issue with parse_json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 852
    },
    "id": "eO6T13guuig2",
    "outputId": "faf8a4dc-508a-419b-ff60-ad39f00003dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7347630 [00:00<448:45:30,  4.55it/s]/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/644475981.py:5: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  interactions_df_new['date_updated'] = interactions_df_new['date_updated'].progress_apply(lambda s: np.datetime64(datetime.strptime(s,format_str)))\n",
      "100%|██████████| 7347630/7347630 [03:25<00:00, 35730.52it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/644475981.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interactions_df_new['date_updated'] = interactions_df_new['date_updated'].progress_apply(lambda s: np.datetime64(datetime.strptime(s,format_str)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1651325</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>271199</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-21 17:23:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651324</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287380</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-21 17:24:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651322</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287381</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-21 17:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651316</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287382</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-21 17:25:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651314</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287388</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-06-21 17:25:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225969</th>\n",
       "      <td>fffff8a718843c0e11dfd93fb41c1297</td>\n",
       "      <td>6606855</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-01 01:37:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225968</th>\n",
       "      <td>fffff8a718843c0e11dfd93fb41c1297</td>\n",
       "      <td>29890569</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-16 14:03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225967</th>\n",
       "      <td>fffff8a718843c0e11dfd93fb41c1297</td>\n",
       "      <td>17256441</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-07 02:50:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225973</th>\n",
       "      <td>fffff8a718843c0e11dfd93fb41c1297</td>\n",
       "      <td>29214708</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-07-08 19:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225966</th>\n",
       "      <td>fffff8a718843c0e11dfd93fb41c1297</td>\n",
       "      <td>7204518</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-12 17:05:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7347630 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  user_id   book_id  rating  \\\n",
       "1651325  00004584d524ec468619e81b176cc991    271199       4   \n",
       "1651324  00004584d524ec468619e81b176cc991    287380       4   \n",
       "1651322  00004584d524ec468619e81b176cc991    287381       4   \n",
       "1651316  00004584d524ec468619e81b176cc991    287382       4   \n",
       "1651314  00004584d524ec468619e81b176cc991    287388       3   \n",
       "...                                   ...       ...     ...   \n",
       "3225969  fffff8a718843c0e11dfd93fb41c1297   6606855       3   \n",
       "3225968  fffff8a718843c0e11dfd93fb41c1297  29890569       3   \n",
       "3225967  fffff8a718843c0e11dfd93fb41c1297  17256441       0   \n",
       "3225973  fffff8a718843c0e11dfd93fb41c1297  29214708       4   \n",
       "3225966  fffff8a718843c0e11dfd93fb41c1297   7204518       0   \n",
       "\n",
       "               date_updated  \n",
       "1651325 2013-06-21 17:23:44  \n",
       "1651324 2013-06-21 17:24:05  \n",
       "1651322 2013-06-21 17:24:31  \n",
       "1651316 2013-06-21 17:25:05  \n",
       "1651314 2013-06-21 17:25:13  \n",
       "...                     ...  \n",
       "3225969 2017-03-01 01:37:24  \n",
       "3225968 2017-03-16 14:03:44  \n",
       "3225967 2017-07-07 02:50:46  \n",
       "3225973 2017-07-08 19:01:43  \n",
       "3225966 2017-07-12 17:05:34  \n",
       "\n",
       "[7347630 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1) parse date \n",
    "interactions_df_new = interactions_df[['user_id', 'book_id', 'rating', 'date_updated']]\n",
    "format_str = '%a %b %d %H:%M:%S %z %Y' #see https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n",
    "#test: datetime_object = datetime.strptime('Fri Jun 21 10:25:05 -0700 2013', format_str) \n",
    "interactions_df_new['date_updated'] = interactions_df_new['date_updated'].progress_apply(lambda s: np.datetime64(datetime.strptime(s,format_str)))\n",
    "\n",
    "#2) sort on user_id, then date\n",
    "interactions_df_new = interactions_df_new.sort_values(by=['user_id', 'date_updated'], ascending=[True,True])\n",
    "display(interactions_df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "Q-mU17Owy8HU",
    "outputId": "54aa3bce-a111-4e65-b4b3-72ffe8cff0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df size 7347630\n",
      "number of unique users: 342415\n",
      "number of unique items: 89411\n",
      "After drop_duplicates (reconsumption items): 7347630 -> 7347630\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>count_item</th>\n",
       "      <th>count_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>271199</td>\n",
       "      <td>2013-06-21 17:23:44</td>\n",
       "      <td>10102</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287380</td>\n",
       "      <td>2013-06-21 17:24:05</td>\n",
       "      <td>1628</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287381</td>\n",
       "      <td>2013-06-21 17:24:31</td>\n",
       "      <td>198</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287382</td>\n",
       "      <td>2013-06-21 17:25:05</td>\n",
       "      <td>247</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287388</td>\n",
       "      <td>2013-06-21 17:25:13</td>\n",
       "      <td>249</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id item_id            datetime  count_item  \\\n",
       "0  00004584d524ec468619e81b176cc991  271199 2013-06-21 17:23:44       10102   \n",
       "1  00004584d524ec468619e81b176cc991  287380 2013-06-21 17:24:05        1628   \n",
       "2  00004584d524ec468619e81b176cc991  287381 2013-06-21 17:24:31         198   \n",
       "3  00004584d524ec468619e81b176cc991  287382 2013-06-21 17:25:05         247   \n",
       "4  00004584d524ec468619e81b176cc991  287388 2013-06-21 17:25:13         249   \n",
       "\n",
       "   count_user  \n",
       "0          24  \n",
       "1          24  \n",
       "2          24  \n",
       "3          24  \n",
       "4          24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping items with less than 5 interactions: 7347630 -> 6686728\n",
      "After dropping users with less than 5 interactions: 6686728 -> 6355864\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>271199</td>\n",
       "      <td>2013-06-21 17:23:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287380</td>\n",
       "      <td>2013-06-21 17:24:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287381</td>\n",
       "      <td>2013-06-21 17:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287382</td>\n",
       "      <td>2013-06-21 17:25:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004584d524ec468619e81b176cc991</td>\n",
       "      <td>287388</td>\n",
       "      <td>2013-06-21 17:25:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id item_id            datetime\n",
       "0  00004584d524ec468619e81b176cc991  271199 2013-06-21 17:23:44\n",
       "1  00004584d524ec468619e81b176cc991  287380 2013-06-21 17:24:05\n",
       "2  00004584d524ec468619e81b176cc991  287381 2013-06-21 17:24:31\n",
       "3  00004584d524ec468619e81b176cc991  287382 2013-06-21 17:25:05\n",
       "4  00004584d524ec468619e81b176cc991  287388 2013-06-21 17:25:13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df size 6355864\n",
      "number of unique users: 148304\n",
      "number of unique items: 26431\n",
      "Sorting by date\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a309c35c5c32f1edbdc5e6770848394a</td>\n",
       "      <td>15067</td>\n",
       "      <td>2006-12-26 15:25:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>53178</td>\n",
       "      <td>2007-02-02 07:14:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>53179</td>\n",
       "      <td>2007-02-02 07:14:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>39916</td>\n",
       "      <td>2007-02-02 07:17:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>25179</td>\n",
       "      <td>2007-02-02 07:18:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id item_id            datetime\n",
       "0  a309c35c5c32f1edbdc5e6770848394a   15067 2006-12-26 15:25:43\n",
       "1  12c1ea7e1c88a03d24f164fc576ef42c   53178 2007-02-02 07:14:38\n",
       "2  12c1ea7e1c88a03d24f164fc576ef42c   53179 2007-02-02 07:14:53\n",
       "3  12c1ea7e1c88a03d24f164fc576ef42c   39916 2007-02-02 07:17:54\n",
       "4  12c1ea7e1c88a03d24f164fc576ef42c   25179 2007-02-02 07:18:04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max date is 2017-11-05 21:19:42, min is 2006-12-26 15:25:43 \n"
     ]
    }
   ],
   "source": [
    "def preprocess_classic(df, minsup=5):\n",
    "    \"\"\"\n",
    "    Goal: - Remove reconsumption items\n",
    "          - Remove items that have less than minsup interactions \n",
    "          - Remove users that have less than minsup interactions \n",
    "               \n",
    "    :input df: Dataframe containing user_id, item_id and time\n",
    "    \"\"\"\n",
    "    before = df.shape[0]\n",
    "    #drop reconsumption items\n",
    "    df = df.drop_duplicates(subset=[\"user_id\",\"item_id\"])\n",
    "    print(\"After drop_duplicates (reconsumption items): {} -> {}\".format(before,df.shape[0]))\n",
    "    #compute item/user counts\n",
    "    g1 = df.groupby('item_id', as_index=False)['user_id'].size()\n",
    "    g1 = g1.rename({'size': 'count_item'}, axis='columns')\n",
    "    g2 = df.groupby('user_id', as_index=False)['item_id'].size()\n",
    "    g2 = g2.rename({'size': 'count_user'}, axis='columns')\n",
    "    df = pd.merge(df, g1, how='left', on=['item_id'])\n",
    "    df = pd.merge(df, g2, how='left', on=['user_id'])\n",
    "    display(df.head(5))\n",
    "    #drop items occurring less than minsup times\n",
    "    before = df.shape[0]\n",
    "    df = df[df['count_item'] >= 35]\n",
    "    print(\"After dropping items with less than {} interactions: {} -> {}\".format(minsup, before,df.shape[0]))\n",
    "    before = df.shape[0]\n",
    "    #drop users with less then minsup items in history\n",
    "    df = df[df['count_user'] >= minsup]\n",
    "    df = df[['user_id','item_id','datetime']]\n",
    "    print(\"After dropping users with less than {} interactions: {} -> {}\".format(minsup, before,df.shape[0]))\n",
    "    return df\n",
    "\n",
    "# just rating >= 3\n",
    "#print(f\"number of unique users: {interactions_df_new['user_id'].nunique()}\")\n",
    "#print(f\"number of unique items: {interactions_df_new['book_id'].nunique()}\")\n",
    "#interactions_df_new = interactions_df_new[interactions_df_new[\"rating\"] >= 3]\n",
    "#print(f\"number of unique users after rating < 3 removal: {interactions_df_new['user_id'].nunique()}\")\n",
    "#print(f\"number of unique items after rating < 3 removal: {interactions_df_new['book_id'].nunique()}\")\n",
    "\n",
    "#print number of users and items\n",
    "interactions_df_processed = interactions_df_new[['user_id','book_id','date_updated']]\n",
    "interactions_df_processed = interactions_df_processed.rename(columns={\"user_id\": \"user_id\", \"book_id\": \"item_id\", \"date_updated\": \"datetime\"})\n",
    "print(f\"df size {interactions_df_processed.shape[0]}\")\n",
    "print(f\"number of unique users: {interactions_df_processed['user_id'].nunique()}\")\n",
    "print(f\"number of unique items: {interactions_df_processed['item_id'].nunique()}\")\n",
    "interactions_df_processed = preprocess_classic(interactions_df_processed)\n",
    "interactions_df_processed.reset_index(drop=True, inplace=True)\n",
    "display(interactions_df_processed.head(5))\n",
    "print(f\"df size {interactions_df_processed.shape[0]}\")\n",
    "print(f\"number of unique users: {interactions_df_processed['user_id'].nunique()}\")\n",
    "print(f\"number of unique items: {interactions_df_processed['item_id'].nunique()}\")\n",
    "interactions_df_processed.sort_values(by=['datetime'], inplace=True)\n",
    "print(\"Sorting by date\")\n",
    "interactions_df_processed.reset_index(inplace=True, drop=True)\n",
    "display(interactions_df_processed.head(5))\n",
    "column = interactions_df_processed[\"datetime\"]\n",
    "print(f\"Max date is {column.max()}, min is {column.min()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipcyUCDUKcOF"
   },
   "source": [
    "# 4. Create consecutive ID's\n",
    "- Working with numpy types != python types\n",
    "- Mapping ID's to consecutive integgers for matrix operations (and scipy sparse matrices, see https://docs.scipy.org/doc/scipy/reference/sparse.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "3XG_uN5VDV7y",
    "outputId": "cab7d63b-306e-427d-ba46-bf363125579e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id             object\n",
       "item_id             object\n",
       "datetime    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "user_id             object\n",
       "item_id              int64\n",
       "datetime    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#change type book_id to numpy.int64\n",
    "display(interactions_df_processed.dtypes)\n",
    "interactions_df_processed['item_id'] = interactions_df_processed['item_id'].astype('int64')\n",
    "display(interactions_df_processed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "Se6PYDzt14vH",
    "outputId": "e72f4925-1031-4843-b4a4-de22c8a34c8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6355864/6355864 [00:08<00:00, 733073.68it/s]\n",
      "100%|██████████| 6355864/6355864 [00:09<00:00, 693112.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>item_id_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a309c35c5c32f1edbdc5e6770848394a</td>\n",
       "      <td>15067</td>\n",
       "      <td>2006-12-26 15:25:43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>53178</td>\n",
       "      <td>2007-02-02 07:14:38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>53179</td>\n",
       "      <td>2007-02-02 07:14:53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>39916</td>\n",
       "      <td>2007-02-02 07:17:54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>25179</td>\n",
       "      <td>2007-02-02 07:18:04</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>38333</td>\n",
       "      <td>2007-02-02 07:18:23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45c3f0e4d05be7eeca4ebb1f88646113</td>\n",
       "      <td>102920</td>\n",
       "      <td>2007-02-14 21:18:46</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45c3f0e4d05be7eeca4ebb1f88646113</td>\n",
       "      <td>23754</td>\n",
       "      <td>2007-02-15 17:45:20</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45c3f0e4d05be7eeca4ebb1f88646113</td>\n",
       "      <td>25103</td>\n",
       "      <td>2007-02-15 17:45:28</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45c3f0e4d05be7eeca4ebb1f88646113</td>\n",
       "      <td>25106</td>\n",
       "      <td>2007-02-15 17:45:29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  item_id            datetime  user_id_int  \\\n",
       "0  a309c35c5c32f1edbdc5e6770848394a    15067 2006-12-26 15:25:43            0   \n",
       "1  12c1ea7e1c88a03d24f164fc576ef42c    53178 2007-02-02 07:14:38            1   \n",
       "2  12c1ea7e1c88a03d24f164fc576ef42c    53179 2007-02-02 07:14:53            1   \n",
       "3  12c1ea7e1c88a03d24f164fc576ef42c    39916 2007-02-02 07:17:54            1   \n",
       "4  12c1ea7e1c88a03d24f164fc576ef42c    25179 2007-02-02 07:18:04            1   \n",
       "5  12c1ea7e1c88a03d24f164fc576ef42c    38333 2007-02-02 07:18:23            1   \n",
       "6  45c3f0e4d05be7eeca4ebb1f88646113   102920 2007-02-14 21:18:46            2   \n",
       "7  45c3f0e4d05be7eeca4ebb1f88646113    23754 2007-02-15 17:45:20            2   \n",
       "8  45c3f0e4d05be7eeca4ebb1f88646113    25103 2007-02-15 17:45:28            2   \n",
       "9  45c3f0e4d05be7eeca4ebb1f88646113    25106 2007-02-15 17:45:29            2   \n",
       "\n",
       "   item_id_int  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  \n",
       "3            3  \n",
       "4            4  \n",
       "5            5  \n",
       "6            6  \n",
       "7            7  \n",
       "8            8  \n",
       "9            9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "\n",
    "#1) convert user uuid to consecutive integer ID's \n",
    "interactions_df_processed['user_id_int'] = interactions_df_processed['user_id'].progress_apply(map_to_consecutive_id)\n",
    "\n",
    "#2) convert book_id to to consecutive integer ID's \n",
    "dct.clear()\n",
    "interactions_df_processed['item_id_int'] = interactions_df_processed['item_id'].progress_apply(map_to_consecutive_id)\n",
    "display(interactions_df_processed.head(10))\n",
    "\n",
    "column = interactions_df_processed['item_id_int'] \n",
    "max_item_id = column.max()\n",
    "\n",
    "column = interactions_df_processed['user_id_int'] \n",
    "max_user_id = column.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>old_user</th>\n",
       "      <th>old_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-12-26 15:25:43</td>\n",
       "      <td>a309c35c5c32f1edbdc5e6770848394a</td>\n",
       "      <td>15067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-02-02 07:14:38</td>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>53178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-02-02 07:14:53</td>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>53179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-02-02 07:17:54</td>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>39916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2007-02-02 07:18:04</td>\n",
       "      <td>12c1ea7e1c88a03d24f164fc576ef42c</td>\n",
       "      <td>25179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355859</th>\n",
       "      <td>96720</td>\n",
       "      <td>21580</td>\n",
       "      <td>2017-11-05 16:21:49</td>\n",
       "      <td>e90ae527118f4e30c4b15b7ff69a0e12</td>\n",
       "      <td>24612600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355860</th>\n",
       "      <td>5968</td>\n",
       "      <td>1671</td>\n",
       "      <td>2017-11-05 19:23:22</td>\n",
       "      <td>617e3285e80e7b7468fd5c69e3d881cd</td>\n",
       "      <td>1270615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355861</th>\n",
       "      <td>69300</td>\n",
       "      <td>186</td>\n",
       "      <td>2017-11-05 19:55:34</td>\n",
       "      <td>f3be22529de075b9b877f4d4ec8025c4</td>\n",
       "      <td>5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355862</th>\n",
       "      <td>60231</td>\n",
       "      <td>186</td>\n",
       "      <td>2017-11-05 20:26:48</td>\n",
       "      <td>e4f0ca741ff5113c25fcd562a8c5aedc</td>\n",
       "      <td>5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355863</th>\n",
       "      <td>13181</td>\n",
       "      <td>10063</td>\n",
       "      <td>2017-11-05 21:19:42</td>\n",
       "      <td>8495d54f2a5413fbfa3f80ee2247ff1f</td>\n",
       "      <td>6839093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6355864 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id            datetime  \\\n",
       "0              0        0 2006-12-26 15:25:43   \n",
       "1              1        1 2007-02-02 07:14:38   \n",
       "2              1        2 2007-02-02 07:14:53   \n",
       "3              1        3 2007-02-02 07:17:54   \n",
       "4              1        4 2007-02-02 07:18:04   \n",
       "...          ...      ...                 ...   \n",
       "6355859    96720    21580 2017-11-05 16:21:49   \n",
       "6355860     5968     1671 2017-11-05 19:23:22   \n",
       "6355861    69300      186 2017-11-05 19:55:34   \n",
       "6355862    60231      186 2017-11-05 20:26:48   \n",
       "6355863    13181    10063 2017-11-05 21:19:42   \n",
       "\n",
       "                                 old_user  old_item  \n",
       "0        a309c35c5c32f1edbdc5e6770848394a     15067  \n",
       "1        12c1ea7e1c88a03d24f164fc576ef42c     53178  \n",
       "2        12c1ea7e1c88a03d24f164fc576ef42c     53179  \n",
       "3        12c1ea7e1c88a03d24f164fc576ef42c     39916  \n",
       "4        12c1ea7e1c88a03d24f164fc576ef42c     25179  \n",
       "...                                   ...       ...  \n",
       "6355859  e90ae527118f4e30c4b15b7ff69a0e12  24612600  \n",
       "6355860  617e3285e80e7b7468fd5c69e3d881cd   1270615  \n",
       "6355861  f3be22529de075b9b877f4d4ec8025c4      5805  \n",
       "6355862  e4f0ca741ff5113c25fcd562a8c5aedc      5805  \n",
       "6355863  8495d54f2a5413fbfa3f80ee2247ff1f   6839093  \n",
       "\n",
       "[6355864 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max user_id is 148303, Max item_id is 26430\n"
     ]
    }
   ],
   "source": [
    "df = interactions_df_processed[['user_id_int', 'item_id_int', 'datetime', 'user_id', 'item_id']].copy().rename(columns={\"user_id_int\": \"user_id\", \"item_id_int\": \"item_id\", \"datetime\": \"datetime\", \"user_id\": 'old_user', \"item_id\": \"old_item\"})\n",
    "display(df)\n",
    "\n",
    "print(f\"Max user_id is {max_user_id}, Max item_id is {max_item_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5084691/5084691 [00:08<00:00, 614707.62it/s]\n",
      "100%|██████████| 1271173/1271173 [00:02<00:00, 584062.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5084691/5084691 [00:09<00:00, 544905.53it/s]\n",
      "100%|██████████| 1271173/1271173 [00:02<00:00, 545667.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5084691/5084691 [00:08<00:00, 596948.65it/s]\n",
      "100%|██████████| 1271173/1271173 [00:02<00:00, 542163.58it/s]\n"
     ]
    }
   ],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('user_id')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            #print(\"%d users sampled\" % i)\n",
    "            #sys.stdout.flush()\n",
    "            pass\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te\n",
    "\n",
    "for iteration in range(3):\n",
    "    print(f\"iteration{iteration}\")\n",
    "    # splitting\n",
    "    train, test = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "\n",
    "    # rebuilding user_id\n",
    "    dct.clear()\n",
    "\n",
    "    train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
    "\n",
    "    dct.clear()\n",
    "\n",
    "    test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n",
    "\n",
    "    dct.clear()\n",
    "\n",
    "    test_tr, test_te = split_train_test_proportion(test)\n",
    "    test_tr.to_csv(f'./test_tr{iteration}.csv', index=False)\n",
    "    test_te.to_csv(f'./test_te{iteration}.csv', index=False)\n",
    "    train.to_csv(f'./train{iteration}.csv', index=False)\n",
    "    test.to_csv(f'./test{iteration}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26430"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tr[\"item_id\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067752/4067752 [00:06<00:00, 614023.11it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016939/1016939 [00:01<00:00, 606019.25it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0      128  2017-09-01 02:23:41  ee0d05672402dfa749653b7b13097ffd   \n",
      "1        1      216  2008-08-19 10:43:58  30ac74c769883b12f6db2262c816ead2   \n",
      "3        2     4172  2013-06-09 21:40:43  9002e18fc10924ec00145e26a1cf72a0   \n",
      "4        3     6615  2016-05-04 20:43:51  1d83ade6f1901e01b3a6a7d5c5f6fab0   \n",
      "5        4    14636  2016-11-25 05:17:09  a8743951826cbac65ed05e69c85dd206   \n",
      "\n",
      "   old_item  \n",
      "0    271265  \n",
      "1    102955  \n",
      "3     52368  \n",
      "4   2418888  \n",
      "5   6345999  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 548859.40it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:02<00:00, 411052.50it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0      128  2017-09-01 02:23:41  ee0d05672402dfa749653b7b13097ffd   \n",
      "2        1    19334  2017-03-06 11:04:31  407a03010634c3d3aa104f7c44c2c6ee   \n",
      "3        2     4172  2013-06-09 21:40:43  9002e18fc10924ec00145e26a1cf72a0   \n",
      "4        3     6615  2016-05-04 20:43:51  1d83ade6f1901e01b3a6a7d5c5f6fab0   \n",
      "5        4    14636  2016-11-25 05:17:09  a8743951826cbac65ed05e69c85dd206   \n",
      "\n",
      "   old_item  \n",
      "0    271265  \n",
      "2  18405520  \n",
      "3     52368  \n",
      "4   2418888  \n",
      "5   6345999  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 544804.23it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:02<00:00, 507428.03it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0      128  2017-09-01 02:23:41  ee0d05672402dfa749653b7b13097ffd   \n",
      "1        1      216  2008-08-19 10:43:58  30ac74c769883b12f6db2262c816ead2   \n",
      "2        2    19334  2017-03-06 11:04:31  407a03010634c3d3aa104f7c44c2c6ee   \n",
      "4        3     6615  2016-05-04 20:43:51  1d83ade6f1901e01b3a6a7d5c5f6fab0   \n",
      "5        4    14636  2016-11-25 05:17:09  a8743951826cbac65ed05e69c85dd206   \n",
      "\n",
      "   old_item  \n",
      "0    271265  \n",
      "1    102955  \n",
      "2  18405520  \n",
      "4   2418888  \n",
      "5   6345999  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 575395.62it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:01<00:00, 514962.16it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "1        0      216  2008-08-19 10:43:58  30ac74c769883b12f6db2262c816ead2   \n",
      "2        1    19334  2017-03-06 11:04:31  407a03010634c3d3aa104f7c44c2c6ee   \n",
      "3        2     4172  2013-06-09 21:40:43  9002e18fc10924ec00145e26a1cf72a0   \n",
      "4        3     6615  2016-05-04 20:43:51  1d83ade6f1901e01b3a6a7d5c5f6fab0   \n",
      "6        4    12100  2012-12-09 00:30:56  15632d9740f8b86b8d7e99f11edc248c   \n",
      "\n",
      "   old_item  \n",
      "1    102955  \n",
      "2  18405520  \n",
      "3     52368  \n",
      "4   2418888  \n",
      "6   7684644  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 561625.27it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:02<00:00, 499924.06it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0      128  2017-09-01 02:23:41  ee0d05672402dfa749653b7b13097ffd   \n",
      "1        1      216  2008-08-19 10:43:58  30ac74c769883b12f6db2262c816ead2   \n",
      "2        2    19334  2017-03-06 11:04:31  407a03010634c3d3aa104f7c44c2c6ee   \n",
      "3        3     4172  2013-06-09 21:40:43  9002e18fc10924ec00145e26a1cf72a0   \n",
      "5        4    14636  2016-11-25 05:17:09  a8743951826cbac65ed05e69c85dd206   \n",
      "\n",
      "   old_item  \n",
      "0    271265  \n",
      "1    102955  \n",
      "2  18405520  \n",
      "3     52368  \n",
      "5   6345999  \n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067752/4067752 [00:07<00:00, 529319.85it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016939/1016939 [00:01<00:00, 526656.80it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0     9239  2013-09-02 13:05:32  07290e6714f98ef10f9b843a6ddf54d2   \n",
      "1        1    12663  2012-07-15 05:25:14  8ab6526c1e17dc9aa1befb767cbfa4e2   \n",
      "3        2    23419  2016-09-08 05:46:58  ba7d7bab66e081c1999c281fc981fb87   \n",
      "4        3    22615  2016-01-27 19:00:30  f5f463ec57f86011c539f1d7cc2bd35e   \n",
      "5        4    22822  2017-01-02 17:48:05  dfd25b244a487a1b3c1aa315794dd316   \n",
      "\n",
      "   old_item  \n",
      "0   6280053  \n",
      "1  10630620  \n",
      "3  27247277  \n",
      "4  25870111  \n",
      "5  25604474  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 542193.42it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:01<00:00, 514866.18it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0     9239  2013-09-02 13:05:32  07290e6714f98ef10f9b843a6ddf54d2   \n",
      "2        1    25319  2017-02-08 06:28:01  48c90de0626f9334e6f621ae4214e2b9   \n",
      "3        2    23419  2016-09-08 05:46:58  ba7d7bab66e081c1999c281fc981fb87   \n",
      "4        3    22615  2016-01-27 19:00:30  f5f463ec57f86011c539f1d7cc2bd35e   \n",
      "5        4    22822  2017-01-02 17:48:05  dfd25b244a487a1b3c1aa315794dd316   \n",
      "\n",
      "   old_item  \n",
      "0   6280053  \n",
      "2  30082505  \n",
      "3  27247277  \n",
      "4  25870111  \n",
      "5  25604474  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 576592.69it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:02<00:00, 497405.67it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0     9239  2013-09-02 13:05:32  07290e6714f98ef10f9b843a6ddf54d2   \n",
      "1        1    12663  2012-07-15 05:25:14  8ab6526c1e17dc9aa1befb767cbfa4e2   \n",
      "2        2    25319  2017-02-08 06:28:01  48c90de0626f9334e6f621ae4214e2b9   \n",
      "4        3    22615  2016-01-27 19:00:30  f5f463ec57f86011c539f1d7cc2bd35e   \n",
      "5        4    22822  2017-01-02 17:48:05  dfd25b244a487a1b3c1aa315794dd316   \n",
      "\n",
      "   old_item  \n",
      "0   6280053  \n",
      "1  10630620  \n",
      "2  30082505  \n",
      "4  25870111  \n",
      "5  25604474  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 538257.07it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:02<00:00, 491741.67it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "1        0    12663  2012-07-15 05:25:14  8ab6526c1e17dc9aa1befb767cbfa4e2   \n",
      "2        1    25319  2017-02-08 06:28:01  48c90de0626f9334e6f621ae4214e2b9   \n",
      "3        2    23419  2016-09-08 05:46:58  ba7d7bab66e081c1999c281fc981fb87   \n",
      "4        3    22615  2016-01-27 19:00:30  f5f463ec57f86011c539f1d7cc2bd35e   \n",
      "6        4     4443  2016-10-26 17:08:57  157e04019ba370c02172a8df2aff238b   \n",
      "\n",
      "   old_item  \n",
      "1  10630620  \n",
      "2  30082505  \n",
      "3  27247277  \n",
      "4  25870111  \n",
      "6    364960  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 544111.92it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:01<00:00, 517679.04it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0     9239  2013-09-02 13:05:32  07290e6714f98ef10f9b843a6ddf54d2   \n",
      "1        1    12663  2012-07-15 05:25:14  8ab6526c1e17dc9aa1befb767cbfa4e2   \n",
      "2        2    25319  2017-02-08 06:28:01  48c90de0626f9334e6f621ae4214e2b9   \n",
      "3        3    23419  2016-09-08 05:46:58  ba7d7bab66e081c1999c281fc981fb87   \n",
      "5        4    22822  2017-01-02 17:48:05  dfd25b244a487a1b3c1aa315794dd316   \n",
      "\n",
      "   old_item  \n",
      "0   6280053  \n",
      "1  10630620  \n",
      "2  30082505  \n",
      "3  27247277  \n",
      "5  25604474  \n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067752/4067752 [00:07<00:00, 522685.54it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016939/1016939 [00:01<00:00, 521872.02it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0    24244  2017-03-25 08:01:02  dd669721e136c1be47d739b14fa23d20   \n",
      "1        1     1948  2013-05-27 07:45:38  95b359d98964316e5b7cd33d0ea6e940   \n",
      "3        2    20170  2017-06-08 05:32:16  8eea88b90159fe51fb97ed09ed72579a   \n",
      "4        3      413  2016-06-09 15:13:43  448d266cf9a737a8e5a0fad159b580b2   \n",
      "5        4      233  2014-11-13 17:08:55  9782d82fdbfa09da49e1b0a5344f4bd4   \n",
      "\n",
      "   old_item  \n",
      "0  29093045  \n",
      "1    294963  \n",
      "3  18667307  \n",
      "4     30220  \n",
      "5    472331  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 541493.48it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:02<00:00, 485059.30it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0    24244  2017-03-25 08:01:02  dd669721e136c1be47d739b14fa23d20   \n",
      "2        1    18309  2013-09-29 12:44:50  6524dab6c11287750ff8d4f8d373b384   \n",
      "3        2    20170  2017-06-08 05:32:16  8eea88b90159fe51fb97ed09ed72579a   \n",
      "4        3      413  2016-06-09 15:13:43  448d266cf9a737a8e5a0fad159b580b2   \n",
      "5        4      233  2014-11-13 17:08:55  9782d82fdbfa09da49e1b0a5344f4bd4   \n",
      "\n",
      "   old_item  \n",
      "0  29093045  \n",
      "2  17785891  \n",
      "3  18667307  \n",
      "4     30220  \n",
      "5    472331  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 531851.24it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:02<00:00, 492226.92it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0    24244  2017-03-25 08:01:02  dd669721e136c1be47d739b14fa23d20   \n",
      "1        1     1948  2013-05-27 07:45:38  95b359d98964316e5b7cd33d0ea6e940   \n",
      "2        2    18309  2013-09-29 12:44:50  6524dab6c11287750ff8d4f8d373b384   \n",
      "4        3      413  2016-06-09 15:13:43  448d266cf9a737a8e5a0fad159b580b2   \n",
      "5        4      233  2014-11-13 17:08:55  9782d82fdbfa09da49e1b0a5344f4bd4   \n",
      "\n",
      "   old_item  \n",
      "0  29093045  \n",
      "1    294963  \n",
      "2  17785891  \n",
      "4     30220  \n",
      "5    472331  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 535147.65it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:02<00:00, 504445.10it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "1        0     1948  2013-05-27 07:45:38  95b359d98964316e5b7cd33d0ea6e940   \n",
      "2        1    18309  2013-09-29 12:44:50  6524dab6c11287750ff8d4f8d373b384   \n",
      "3        2    20170  2017-06-08 05:32:16  8eea88b90159fe51fb97ed09ed72579a   \n",
      "4        3      413  2016-06-09 15:13:43  448d266cf9a737a8e5a0fad159b580b2   \n",
      "6        4     2577  2016-01-26 17:37:46  aed07d8f90b4391ce1b1c7415f606b85   \n",
      "\n",
      "   old_item  \n",
      "1    294963  \n",
      "2  17785891  \n",
      "3  18667307  \n",
      "4     30220  \n",
      "6    507689  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4067753/4067753 [00:07<00:00, 555301.61it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
      "100%|██████████| 1016938/1016938 [00:01<00:00, 519824.05it/s]\n",
      "/var/folders/lj/fplmjk8x0jjd124my50m83080000gn/T/ipykernel_1946/1800135781.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id             datetime                          old_user  \\\n",
      "0        0    24244  2017-03-25 08:01:02  dd669721e136c1be47d739b14fa23d20   \n",
      "1        1     1948  2013-05-27 07:45:38  95b359d98964316e5b7cd33d0ea6e940   \n",
      "2        2    18309  2013-09-29 12:44:50  6524dab6c11287750ff8d4f8d373b384   \n",
      "3        3    20170  2017-06-08 05:32:16  8eea88b90159fe51fb97ed09ed72579a   \n",
      "5        4      233  2014-11-13 17:08:55  9782d82fdbfa09da49e1b0a5344f4bd4   \n",
      "\n",
      "   old_item  \n",
      "0  29093045  \n",
      "1    294963  \n",
      "2  17785891  \n",
      "3  18667307  \n",
      "5    472331  \n"
     ]
    }
   ],
   "source": [
    "# folds\n",
    "\n",
    "counter = 0\n",
    "for iteration in range(3):\n",
    "    df = pd.read_csv(f\"train{iteration}.csv\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True) # Define the split - into 5 folds \n",
    "    print(kf.get_n_splits(df))\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train = df.iloc[train_index]\n",
    "        test = df.iloc[test_index]\n",
    "\n",
    "        # rebuilding user_id\n",
    "        dct.clear()\n",
    "\n",
    "        train['user_id'] = train['user_id'].progress_apply(map_to_consecutive_id)\n",
    "\n",
    "        dct.clear()\n",
    "\n",
    "        test['user_id'] = test['user_id'].progress_apply(map_to_consecutive_id)\n",
    "\n",
    "        dct.clear()\n",
    "\n",
    "        test_tr, test_te = split_train_test_proportion(test)\n",
    "        test_tr.to_csv(f'./test_tr_fold{counter}.csv', index=False)\n",
    "        test_te.to_csv(f'./test_te_fold{counter}.csv', index=False)\n",
    "        train.to_csv(f'./train_fold{counter}.csv', index=False)\n",
    "        test.to_csv(f'./test_fold{counter}.csv', index=False)\n",
    "        print(train.head())\n",
    "        counter+=1\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
